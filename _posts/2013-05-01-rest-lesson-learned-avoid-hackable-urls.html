---
layout: post
title: "REST lesson learned: Avoid hackable URLs"
date: 2013-05-01 10:29 UTC
tags: [Software Design, Services, REST]
---
{% include JB/setup %}

<div id="post">
	<p>
		<em>Avoid hackable URLs if you are building a HATEOAS API.</em>
	</p>
	<p>
		This is a <a href="http://blog.ploeh.dk/2013/04/29/rest-lessons-learned">lesson about REST API design that I learned while building non-trivial REST APIs</a>. If you provide a full-on <a href="http://martinfowler.com/articles/richardsonMaturityModel.html">level 3</a> REST API, consider avoiding hackable URLs.
	</p>
	<p>
		<strong>Hackable URLs</strong>
	</p>
	<p>
		A <em>hackable URL</em> is a URL where there's a clear pattern or template for constructing the URL. As an example, if I present to you the URL <code>http://foo.ploeh.dk/products/1234</code>, it's easy to guess that this is a resource representing a product with the SKU of <em>1234</em>. If you know the SKU of another product, it's easy to 'hack' the URL to produce e.g. <code>http://foo.ploeh.dk/products/5678</code>.
	</p>
	<p>
		That's a really nice feature of your API if you are doing a <a href="http://martinfowler.com/articles/richardsonMaturityModel.html">level 1 or 2</a> API, but for a <a href="http://en.wikipedia.org/wiki/HATEOAS">HATEOAS</a> API, this defies the purpose.
	</p>
	<p>
		<strong>The great divide</strong>
	</p>
	<p>
		Please notice that the shift from level 2 to level 3 RESTful APIs mark a fundamental shift in the way you should approach URL design.
	</p>
	<p>
		<img src="/content/binary/great-divide-between-richardson-level-2-and-3.png">
	</p>
	<p>
		Hackable URLs are great for level 1 and 2 APIs because the way you (as a client) are told to construct URLs is by assembling them from templates. As <a href="http://msdn.microsoft.com/en-us/library/windowsazure/dd179370.aspx">an example</a>, the Windows Azure REST APIs explicitly instruct you to construct the URL in a particular way: the URL to get BLOB container properties is <code>https://myaccount.blob.core.windows.net/mycontainer?restype=container</code>, where you should replace <em>myaccount</em> with your account name, and <em>mycontainer</em> with your container name. While code aesthetics are subjective, it's not even a particularly <a href="http://en.wikipedia.org/wiki/Clean_URL">clean URL</a>, but it's easy enough to produce. The URL template is part of the contract, which puts the Windows Azure API solidly at level 2 of the Richardson Maturity Model. If I were designing a level 1 or 2 API, I'd make sure to make URLs hackable, too.
	</p>
	<p>
		However, if you're building a level 3 API, hypermedia is king. Clients are expected to <em>follow links</em>. The addresses of resources are <em>not</em> published as having a particular template; instead, clients must follow semantic links in order to arrive at the desired resource(s). When hypermedia is the engine of application state, it's no good if the client can short-circuit the application flow by 'hacking' URLs. It may leave the application in an inconsistent state if it tries to do that.
	</p>
	<p>
		Hackable URLs are great for level 1 and 2 APIs, but counter-productive for level 3 APIs.
	</p>
	<p>
		<strong>Evolving URLs</strong>
	</p>
	<p>
		One of the main attractions of building a level 3 RESTful API is that it's easier to evolve. Exactly because URL templates are <em>not</em> part of the contract, you can decide to change the URL structure when evolving your API.
	</p>
	<p>
		Imagine that the first version of your API has an (internal) URL template like <code>/orders/{customerId}</code>, so that the example URL <code>http://foo.ploeh.dk/orders/1234</code> is the address of the order history for customer <em>1234</em>. However, in version 2 of your API, you realize that this way of thinking is still too RPC-like, and you'd rather prefer <code>/customers/{customerId}/order</code>, e.g. <code>http://foo.ploeh.dk/customers/1234/orders</code>.
	</p>
	<p>
		With a level 3 RESTful API, you can change your internal URL templates, and as long as you keep providing links, clients following links will not notice the difference. However, if clients are 'hacking' your URLs, their applications may stop working if you change URL templates.
	</p>
	<p>
		<strong>Keep clients safe</strong>
	</p>
	<p>
		In the end, HATEOAS is about encapsulation: make it easy for the client to do the right thing, and make it hard for the client to do the wrong thing. Following links will make clients more robust, because they will be able to handle changes in the API. Making it easy for clients to follow links is one side of designing a good API, but the other side is important too: make it difficult for clients to <em>not</em> follow links: make it difficult for clients to 'hack' URLs.
	</p>
	<p>
		The services I've helped design so far are level 3 APIs, but they still used hackable URLs. One reason for that was that this is the default in the implementation platform we used (<a href="http://www.asp.net/web-api">ASP.NET Web API</a>); another reason was that I thought it would be easier for me and the rest of the development team if the URLs were human-readable. Today, I think this decision was a mistake.
	</p>
	<p>
		What's the harm of supplying human-readable URLs for a level 3 RESTful API? After all, if a client only follows links, the values of the URLs shouldn't matter.
	</p>
	<p>
		Indeed, <em>if</em> the client only follows links. However, clients are created by human developers, and humans often take the road of least resistance. While there are long-time benefits (robustness) from following links, it <em>is</em> more work in the short term. The API team and I repeatedly experienced that the developers consuming our APIs had 'hacked' our URLs; when we changed our URL templates, their clients broke and they complained. Even though we had tried to explicitly tell them that they <em>must</em> follow links, they didn't. While we <em>never</em> documented our URL templates, they were simply too easy to guess from pure extrapolation.
	</p>
	<p>
		<strong>Opaque URLs</strong>
	</p>
	<p>
		In the future, I plan to make URLs opaque when building level 3 APIs. Instead of <code>http://foo.ploeh.dk/customers/1234/orders</code>, I'm going to make it <code>http://foo.ploeh.dk/DC884298C70C41798ABE9052DC69CAEE</code>, and instead of <code>http://foo.ploeh.dk/products/2345</code>, I'm going to make it <code>http://foo.ploeh.dk/598CB0CAC30646E1BB768596BFE91F2C</code>, and so on.
	</p>
	<p>
		Obviously, that means that my API will have to maintain some sort of two-way lookup table that can map DC884298C70C41798ABE9052DC69CAEE to a request for customer <em>1234</em>'s orders, 598CB0CAC30646E1BB768596BFE91F2C to request for product <em>2345</em>, but that's trivial to implement.
	</p>
	<p>
		It puts a small burden on the server(s), but effectively stops client developers from shooting themselves in their feet.
	</p>
	<p>
		<strong>Summary</strong>
	</p>
	<p>
		Hackable URLs are a good idea if you are building a web site, or a level 1 or 2 REST API, but unless you know that all client developers are enthusiastic RESTafarians, consider producing opaque URLs for level 3 REST APIs.
	</p>
</div>

<div id="comments">
<hr>
<h2 id="comments-header">Comments</h2>
	<div class="comment">
		<div class="comment-author">
			<a href="https://github.com/JontyMC">Jon Curtis</a>
		</div>
		<div class="comment-content">
			<p>
				I understand the benefits of the idea that clients must follow links, I just can't see how it would work in reality. Say you are building a website to display products and you are consuming a rest API, how do you support deep linking to individual products? OK, you can either use the same URL as the underlying API or encode it in, but what are you expected to do if the API changes it's links? Redirect the user to your home page? What if you want to display information from 2 or more resources on the same webpage?
			</p>
		</div>
		<div class="comment-date">2013-05-15 8:04 UTC</div>
	</div>
	<div class="comment">
		<div class="comment-author">
			<a href="http://blog.ploeh.dk/">Mark Seemann</a>
		</div>
		<div class="comment-content">
			<p>
				First of all, keep in mind that while it can be helpful to think about REST design principles in terms of "how would I design this if it was a web site", a REST API is <em>not</em> a web site.
			</p>
			<p>
				You can do deep linking in your web site, but why would you want to do 'deep linking' for an API? These are two different concerns.
			</p>
			<p>
				It's very common to create a web site where each page calls many individual services. This can be done either from the web server (e.g. from ASP.NET or similar), or from the browser as AJAX calls. This is commonly known as <em>mash-up architecture</em>, because the GUI is really just a mash-up of service data. Amazon.com works that way. You can still deep link to a web page; it's the web page's responsibility to figure out which services to call with what parameters.
			</p>
			<p>
				That said, as described in the <a href="http://amzn.to/YFnkRg">RESTful Web Services Cookbook</a>, you should serve <a href="http://www.w3.org/Provider/Style/URI.html">cool URLs</a>, so if you ever decide to change your internal URI template, you should leave a <a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html#sec10.3.2">301 (Moved Permanently)</a> behind at the old URL. This would enable a client that once bookmarked a resource to follow the redirect to the new address.
			</p>
		</div>
		<div class="comment-date">2013-05-15 9:11 UTC</div>
	</div>
	<div class="comment">
		<div class="comment-author">
			<a href="https://github.com/JontyMC">Jon Curtis</a>
		</div>
		<div class="comment-content">
			<p>
				When you say "it's the web page's responsibility to figure out which services to call", that's what I'm getting at, how would the client do that?
			</p>
			<p>
				I'm guessing one way would be to cache links followed and update them on 301s or "re-follow" on 404s. So, say you wanted a web page displaying "product/24", you might:
			</p>
			<ul>
				<li>GET the REST endpoint</li>
				<li>GET product catalogue URL from response</li>
				<li>GET product URL from response</li>
				<li>Cache the product URL against the website product URL</li>
				<li>Subsequent requests hit the cached URL</li>
			</ul>
			<p>
				Then if the product URL changes, if the response is 301, you simply update the cache. If the response is 404 then you'd redo the above steps.
			</p>
			<p>
				I'm just thinking this through, is the above a "standard" approach for creating rest clients?
			</p>
		</div>
		<div class="comment-date">2013-05-15 12:04 UTC</div>
	</div>	
	<div class="comment">
		<div class="comment-author">
			<a href="http://blog.ploeh.dk/">Mark Seemann</a>
		</div>
		<div class="comment-content">
			<p>
				That sounds like one way of doing it. I don't think there's a 'standard' way for creating RESTful clients.
			</p>
			<p>
				The sketch you paint sounds like a lot of work, and it <em>seems</em> that it would be easier if the client could simply assemble appropriate URLs from templates. That would indicate level 1 and 2 REST APIs, which might be perfectly fine if the only purpose of building the service is to support a GUI. However, what you get in exchange for the extra effort it takes to consume a level 3 API, is better decoupling. It's always going to be a trade-off.
			</p>
			<p>
				It's definitely going to be more work to build and consume a truly HATEOAS-based API, so you should only do it if it's going to provide a good return on investment. When would that be? One general scenario I can think of is when you're building a service, which is going to be consumed by multiple (unknown) clients. If you control the service, but not the clients, I'd say a level 3 API is very beneficial, because it enables you to evolve the API independently of the clients. Conversely, if the only purpose of building a service is to support a single client, it's probably going to be overkill.
			</p>
		</div>
		<div class="comment-date">2013-05-15 15:15 UTC</div>
	</div>
	<div class="comment">
		<div class="comment-author">
			<a href="https://github.com/redben">Reda Bendiar</a>
		</div>
		<div class="comment-content">
			<p>
				The way I see it is that being HATEOAS compliant does not impose non-hackable URLs, but that URLs - even if they might look hackable (/1, /2...etc) - are not guaranteed to work, are not part of the contract and thus should not be relied uppon. In other words, a link is only guaranteed to work if you, the client, got it from a previous reponse, be it "hackable-looking" or not.
			</p>
			<p>
				So I think opaque URLs are just a way to inforce that contract. But don't we always here that "a good REST client should be well behaved" ?
			</p>
		</div>
		<div class="comment-date">2014-10-10 11:11 UTC</div>
	</div>
	<div class="comment">
		<div class="comment-author">
			<a href="http://blog.ploeh.dk/">Mark Seemann</a>
		</div>
		<div class="comment-content">
			<p>
				Reda, thank you for writing. You're right, and if we could rely on all clients to be well-behaved, there'd be no problems. However, in my experience, client developers often don't read the documentation particularly thoroughly. Instead, they look at the returned data and start inferring the URL scheme from examples. I already wrote about this in this post:
				<blockquote>"The API team and I repeatedly experienced that the developers consuming our APIs had 'hacked' our URLs; when we changed our URL templates, their clients broke and they complained. Even though we had tried to explicitly tell them that they <em>must</em> follow links, they didn't."</blockquote>
				So, in this imperfect world, non-hackable URLs start to look attractive, because then the client developers have no choice but to follow the links.
			</p>
		</div>
		<div class="comment-date">2014-10-10 12:02 UTC</div>
	</div>
	<div class="comment">
		<div class="comment-author">
			<a href="http://kijanawoodard.com/">Kijana Woodard</a>
		</div>
		<div class="comment-content">
			<p>
				I'd like to propose an alternate strategy to achieve the desired result while maintaining 
				the ability to easily debug production issues at the client: 
				only use the non-hackable urls for the "dev sandbox".
			</p>	
			<p>
				Another inducement to better client behvior might be to have the getting started documentation
				use existing libraries for the chosen hypermedia media type.
			</p>	
			<p>
				Finally, have the clients send a "developer [org] identifier". Find a way to probe clients for 
				correctness. For instance, occasionally alter hrefs, but also support the "hackable" form.
			</p>	
			<p>
				With this data, be proactive about informing the user that
				"we're planning a release and your app will probably break because 
				you're not following links as expected".
			</p>
			<p>
				In the end, some people will still fail and be angry. With opaque urls, I would worry that users 
				would have a hard time communicating production issues when looking at logs /fiddler / browser tools / etc.
			</p>
		</div>
		<div class="comment-date">2014-12-23 17:40 UTC</div>
	</div>
	<div class="comment">
		<div class="comment-author"><a href="http://blog.ploeh.dk">Mark Seemann</a></div>
		<div class="comment-content">
			<p>
				Kijana, thank you for writing. You suggest various good ideas that I'll have to keep in mind. Not all of them are universally applicable, but then I also don't think that my suggestion should be applied indiscriminately.
			</p>
			<p>
				Your first suggestion assumes that there <em>is</em> a dev sandbox; this may or may not be the case. The APIs with which I currently work have no dev sandboxes.
			</p>
			<p>
				The idea about using existing client libraries for the chosen hypermedia type is only possible if such libraries exist. The APIs I currently design use vendor media types, so client libraries only exist if we develop them ourselves. However, one of the important goals of RESTful services is to ensure interoperability, so we can't assume that clients are going to run on .NET, or Java, or Ruby, or whatever. For vendor media types, I don't think this is a viable option.
			</p>
			<p>
				Using a client identifier is an option, but in order to work well, there must be some way to correlate that identifier to a contact in the client's organisation. That's an option if you already have a mechanism in place where you only allow known clients to access your API. On the other hand, if you publish a truly scalable public API, you may not want to do that, as registration requirements tend to hurt adoption. The APIs I currently work with is a mix of both of those; some are publicly accessible, while others require a 'client key'.
			</p>
			<p>
				These are all interesting ideas, but ultimately, I'm not sure I understand your concern. Let's first establish that 'users' are other <em>programmers</em>. Why would a URL like <code>http://foo.ploeh.dk/DC884298C70C41798ABE9052DC69CAEE</code> be harder to communicate than <code>http://foo.ploeh.dk/customers/1234/orders</code>? Isn't it copy and paste in both cases?
			</p>
			<p>
				To be clear: I don't claim that obfuscated URLs don't make client developers' work more difficult; it does, compared to 'cheating' by hacking the URL schemes, instead of following links. Even for well-behaved client developers, another level of abstraction always makes things harder. On the other hand, this should also make clients more robust, so as always, it's a trade-off.
			</p>
		</div>
		<div class="comment-date">2015-01-22 08:55 UTC</div>
	</div>
	<div class="comment">
		<div class="comment-author"><a href="https://twitter.com/dkubb">Dan Kubb</a></div>
		<div class="comment-content">
			<p>
				<blockquote>&ldquo;The API team and I repeatedly experienced that the developers consuming our APIs had 'hacked' our URLs; when we changed our URL templates, their clients broke and they complained. Even though we had tried to explicitly tell them that they <em>must</em> follow links, they didn't.&rdquo;</blockquote>
			</p>
			<p>
				I recently worked on an API for an iOS app and we ran into the same problem. It didn't matter how often I said "these URLs are probably going to change, don't hard-code them into the app" we still ran into issues. This was an internal team, I can only imagine how much more difficult it would be with an external team.
			</p>
			<p>	
				Instead of hashing the URLs, we changed the server-side URL generation to HMAC the URL and append the signature onto the query string. Requests without a valid signature would return a 403 Forbidden response. The root of the domain is the only URL that doesn't require a signature, and it returns a json response with signed URLs for each of the "base" resources.
			</p>
			<p>
				We enabled this on a staging server and since all dev was happening on it, all the hard-coded URLs stopped functioning and were quickly removed from the application. It forced both us and the iOS developers to think more about navigation between resources, since it was impossible to get from one resource to another without valid URLs included in the json responses. I think it was probably also nicer for debugging than hashed URLs would be.
			</p>
		</div>
		<div class="comment-date">2015-04-11 09:26 UTC</div>
	</div>
	<div class="comment">
		<div class="comment-author"><a href="http://blog.ploeh.dk">Mark Seemann</a></div>
		<div class="comment-content">
			<p>
				Dan, thank you for sharing that great idea! That looks like a much better solution than my original suggestion of obscuring the URL, because the URL is still human-readable, and thus probably still easier to troubleshoot for developers.
			</p>
			<p>
				Your suggestion also doesn't require a lookup table. My suggested solution would require a lookup table in order to understand what each obscured URL actually <em>means</em>, and if you're running on multiple servers, that lookup table would have to be kept consistent across all servers, which can be hard to do in itself (you can use a database, but then you'd have a single point of failure). Your solution doesn't need any of that; it only requires that the HMAC key is the same on all servers.
			</p>
			<p>
				The only disadvantage that I can think of is that you may need to keep that HMAC key secret, particularly in internal projects, in order to prevent clients from (literally) hacking the URLs.
			</p>
			<p>
				Still, it sounds like your solution has more advantages, so I'm going to try that approach next time. Thank you for sharing!
			</p>
		</div>
		<div class="comment-date">2015-04-11 10:21 UTC</div>
	</div>
	<div class="comment">
		<div class="comment-author"><a href="https://twitter.com/dkubb">Dan Kubb</a></div>
		<div class="comment-content">
			<p>
				<blockquote>&ldquo;The only disadvantage that I can think of is that you may need to keep that HMAC key secret, particularly in internal projects, in order to prevent clients from (literally) hacking the URLs.&rdquo;</blockquote>
			</p>
			<p>
				That was one concern of ours too. One approach we considered was including the git commit SHA as part of the HMAC secret so that every commit would invalidate existing URLs. We decided against it because we were doing Continous Delivery, so multiple times a day we were deploying to the server, and we didn't want the communication overhead of having to notify everyone on each commit. We wanted to be able to merge feature branches into master and just know the CI server was going to handle deployment; and that unless we got alerts from CI, Pingdom or New Relic, everything is working as expected. The last thing we wanted to do was babysit the build so we could tell everyone "ok, the new build has deployed to staging, URLs will break so restart any clients you are in the middle of testing". Also part of the reason we use REST (and json-api) was to decouple front and backend development, it seemed counterproductive to introduce coupling <em>back</em> into the process.
			</p>
			<p>
				An internal team could still re-implement this whole mechanism and sign their own URLs. We could either generate random secrets every day or have a simple tool that we can use to change the secret at-will (probably both).
			</p>
			<p>
				Even though it doesn't completely stop URL hard coding, another idea we had was to include an expiration timestamp in the query string and then HMAC the URL with the timestamp included. We would use the responses' Cache-Control max-age to calculate the time, which would allow the client to use any URLs from cached responses. If the client didn't implement proper cache invalidation the URLs would inexplicably break, thus having a nice side-effect of forcing the client to handle Cache-Control max-age properly.
			</p>
		</div>
		<div class="comment-date">2015-04-11 17:58 UTC</div>
	</div>
	<div class="comment">
		<div class="comment-author"><a href="http://blog.ploeh.dk">Mark Seemann</a></div>
		<div class="comment-content">
			<p>
				Dan, there are lots of interesting ideas there. What I assumed from your first comment is that you'd calculate the HMAC using asymmetric encryption, which would mean that unless clients have the server's encryption key, they wouldn't be able to recalculate the HMAC, and that would effectively prevent them from attempting to 'guess' URLs instead of following links.
			</p>
			<p>
				If an external client has the server's encryption key, you have a different sort of problem.
			</p>
			<p>
				However, for internal clients, developers may actually be able to find the key in your source control repository, build server, or wherever else you keep it (depending on the size of your organisation). You can solve this with security measures, like ACL-based security on the crypto key itself. It not hard, but it's something you may explicitly have to do.
			</p>
			<p>
				When it comes to tying the URL to cache invalidation, that makes me a bit uneasy. While RESTful clients should follow links, they are allowed to <em>bookmark</em> links. It's a fundamental tenet of proper web design (not only REST) that <a href="http://www.w3.org/Provider/Style/URI">cool URIs don't change</a>. A client should be allowed to keep a particular URL around <em>forever</em>, and a service following <a href="http://en.wikipedia.org/wiki/Robustness_principle">Postel's law</a> should keep honouring requests for that URL. As the <a href="http://amzn.to/YFnkRg">RESTful Web Services Cookbook</a> explains, if you move the resource, you should at least return a 301 (Moved Permanently) "or, in rare cases," issue a 410 (Gone) response.
			</p>
		</div>
		<div class="comment-date">2015-04-12 11:35 UTC</div>
	</div>
	<div class="comment">
		<div class="comment-author">Sandro Magi</div>
		<div class="comment-content">
			<p>As Dan said, you can use an HMAC to protect certain parameters in a URL from tampering. I actually formalized this approach in a .NET library I call <a href="https://higherlogics-trac.sourcerepo.com/higherlogics_clavis/wiki/WikiStart">Clavis</a>, and which I first discussed in detail <a href="http://higherlogics.blogspot.ca/2014/01/clavis-rebooted-secure-type-safe-urls.html">here</a>.</p>
			<p>Clavis just provides a simple framework for declaring a resources parameter interface. Given that interface, Clavis provides a way to generate URLs when given a valid set of parameters, and also provides a way to safely parse values given a constructed URL. Arbitrary types can be specified as resource parameters, and there's very little boilerplate to convert to/from strings.</p>
			<p>Parameters are protected from tampering by default, but you can declare that some are unprotected, meaning the client can change them without triggering a server validation error. You want this in some cases, for instance to support GET forms, like a search.</p>
		</div>
		<div class="comment-date">2015-04-12 12:16 UTC</div>
	</div>
	<div class="comment">
		<div class="comment-author"><a href="http://ruben.verborgh.org">Ruben Verborgh</a></div>
		<div class="comment-content">
			<p>Late to the party, but I wonder how you will create a hypermedia form that generates <code>http://foo.ploeh.dk/598CB0CAC30646E1BB768596BFE91F2C</code> rather than <code>http://foo.ploeh.dk/products/2345</code>.</p>
			<p>In the case of hyperlinks, I fully agree: linking to a product should not require an specifically structured identifier. However, hypermedia is more than links alone: what if the client wants to navigate to product with a given tracking number, or a list of people with a given first name?</p>
			<p>“Hackable URIs” are not a <em>necessity</em> for REST, but they are a potential/likely consequence of hypermedia forms. Such forms can be described with less expressive power if only simple string replacements are required instead of more complex transformations.</p>
		</div>
		<div class="comment-date">2016-02-25 11:20 UTC</div>
	</div>
	<div class="comment">
		<div class="comment-author"><a href="http://blog.ploeh.dk">Mark Seemann</a></div>
		<div class="comment-content">
			<p>
				Ruben, thank you for writing. This is a commonly occuring requirement, particularly when searching for particular resources, and I usually solve it with URI templates, as outlined in the <a href="http://amzn.to/YFnkRg">RESTful Web Services Cookbook</a>. Essentially, it involves providing URI templates like <code>http://foo.ploeh.dk/0D89C19343DA4ED985A492DA1A8CDC53/{term}</code>, and making sure that each template is served like a link, with a particular relationship type. For example:
			</p>
			<p>
				<pre style="font-family:Consolas;font-size:13;color:black;"><span style="color:blue;">&lt;</span><span style="color:#a31515;">home</span><span style="color:blue;">&nbsp;</span><span style="color:red;">xmlns</span><span style="color:blue;">=</span>&quot;<span style="color:blue;">http://fnaah.ploeh.dk/productcatalog/2013/05</span>&quot;<span style="color:blue;">&gt;</span>
<span style="color:blue;">&nbsp;&nbsp;&lt;</span><span style="color:#a31515;">link-template</span><span style="color:blue;">&nbsp;</span><span style="color:red;">href</span><span style="color:blue;">=</span>&quot;<span style="color:blue;">http://foo.ploeh.dk/0D89C19343DA4ED985A492DA1A8CDC53/{term}</span>&quot;
<span style="color:blue;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="color:red;">rel</span><span style="color:blue;">=</span>&quot;<span style="color:blue;">http://catalog.api.ploeh.dk/docs/rels/product/search</span>&quot;<span style="color:blue;">&nbsp;/&gt;</span>
<span style="color:blue;">&lt;/</span><span style="color:#a31515;">home</span><span style="color:blue;">&gt;</span></pre>				
			</p>
			<p>
				It isn't perfect, but the best I've been able to come up with, and it works fairly well in practice.
			</p>
		</div>
		<div class="comment-date">2016-03-02 19:25 UTC</div>
	<div class="comment">
		<div class="comment-author"><a href="http://ruben.verborgh.org">Ruben Verborgh</a></div>
		<div class="comment-content">
			<p>
				Sure, URI templates are a means for creating hypermedia controls. But the point is that what they generate are hackable URIs.
			</p>
			<p>
				You still have a (semi-)hackable URI with <code>http://foo.ploeh.dk/0D89C19343DA4ED985A492DA1A8CDC53/{term}</code>. Even though the <code>/0D89C19343DA4ED985A492DA1A8CDC53/</code> part is non-manipulable, terms can still be changed at the end. This shows that hackable URIs cannot entirely be avoided if we want to keep hypermedia controls simple. What else are hackable URIs but underspecified, out-of-band hypermedia controls?
			</p>
			<p>
				An in-band IRI template makes the message follow the REST style by putting the control inside of the message, but it results in a hackable IRI. So, apparently, an HTTP REST API without hackable URIs is hard when there's more than just links.
			</p>
		</div>
		<div class="comment-date">2016-03-02 19:45 UTC</div>
	</div>
</div>
